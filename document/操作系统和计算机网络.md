# 操作系统

### 进程和线程

#### 1、线程和进程的区别和联系

​	进程是系统资源分配的最小单位，线程是程序执行的最小单位；

​	进程使用独立的数据空间，而线程共享进程的数据空间。

#### 2、线程的调度算法

#### 	2.1 先来先服务调度（队列）

​		可用于**作业调度**，也可用于**进程调度**。

​		缺点：比较有**利于长作业**，而**不利于短作业**。 **有利于CPU繁忙**的作业，而**不利于I/O繁忙**的作业。

#### 	**2.2 最短优先**

​		对短作业或短进程优先调度的算法

​		短作业优先(SJF)，后备队列中选择一个或若干个运行时间最短的作业，调入内存运行

​		短进程优先(SPF)，就绪队列汇总选出一个估计运行时间最短的进程，分配处理机，立即执行并执行完成，或发生某事件被阻塞放弃处理机时重新调度

​		缺点：长时间的运行得不到保证

#### 	**2.3时间片轮转**

​		专门为分时系统设计的(系统能在给定时间响应所有用户请求)

​		将一个较小时间单元定义为时间量或时间片。时间片的大小通常为 10~100ms。就绪队列作为循环队列。CPU 调度程序循环整个就绪队列，为每个进程分配不超过一个时间片的 CPU。

#### 	**2.4优先级调度**

##### 		**2.4.1非抢占式优先权算法**

​		场景：用于**批处理**或者**实时性要求不严**的实时系统

​		系统一旦将处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成

​		发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程

##### 		**2.4.2抢占式优先权调度算法**

​		场景：要求比较严格的**实时系统**中，以及对**性能要求较高的批处理和分时系统**中

​		将处理机分配给优先权最高的进程

​		其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程



### 3.线程切换的步骤

#### 		**3.1线程切换**：切换内核栈和硬件上下文

#### 		**3.2上下文切换**：CPU通过分配时间片来执行任务，当一个任务的时间片用完，就会切换到另一个任务。在切换之前会保存上一个任务的状态，当下次再切换到该任务，就加载这个状态(任务从保存到再加载的过程就是一次上下文切换)

​		切出：一个线程被剥夺处理器的使用权而暂停运行

​		切入：一个线程被系统选中占用处理器开始或继续运行

#### 		**3.3切换开销**：最显著的性能损耗就是保存寄存器中的内容

​						  	CPU高速缓存失效

​							页表查找是很慢的过程，通常使用Cache来缓存常用地址映射，这样可以加速页表查找。一旦切换，cache失效就会导				致命中率降低，虚拟地址转为物理地址就会变慢，就是程序运行会变慢

#### 		**3.4引起切换的原因**		

​				1、当前执行任务的时间片用完之后，系统CPU正常调度下一个任务

​				2、当前执行任务碰到IO阻塞，调度器将此任务挂起，继续下一任务

​				3、多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一任务

​				4、用户代码挂起当前任务，让出CPU时间

​				5、硬件中断

#### 	**3.5如何减少上下文切换**

​				**无锁并发编程：**多线程竞争时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照hash取模分段，不同的线程处理不同的数据

​				**CAS算法：**Java的Atomic包使用CAS算法来更新数据，不需要加锁

​				**使用最少线程**：避免创建不需要的线程

​				**协程**：在单线程里实现多任务的调整，并在单线程里维持多个任务间的切换

### **4.内存屏障**

#### 		**4.1为什么会有内存屏障**

​		每个CPU都有自己的缓存，缓存的目的就是为了提高性能，避免每次都向内存取。弊端就是不能实时和内存发生信息交换，分在不同CPU执行的不同线程对同一个变量缓存值不同		

#### 		**4.2内存屏障的作用**		

​		1.阻止屏障两侧的**指令重排序**

​		2.强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中对应的数据失效

#### 		**4.3内存屏障是什么**

​		硬件层的内存屏障分为两种：Load Barrier和Store Barrier即读屏障和写屏障

​		对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从主内存加载数据

​		对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见		

#### 		**4.4java中的内存屏障**	

​		java的内存屏障通常所谓的四种即**`LoadLoad`,`StoreStore`,`LoadStore`,`StoreLoad`**实际上也是上述两种的组合，完成一系列的屏障和数据同步功能

​		**LoadLoad屏障**：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。

​		**StoreStore屏障**：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。

​		**LoadStore屏障**：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。

​		**StoreLoad屏障**：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。***它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能\***

#### 		**4.5volatile中的内存屏障**

​		在每个volatile写操作前插入**StoreStore屏障**，在写操作后插入**StoreLoad屏障**；

​		在每个volatile读操作前插入**LoadLoad屏障**，在读操作后插入**LoadStore屏障**；

​		由于内存屏障的作用，避免了volatile变量和其它**指令重排序**、线程之间实现了通信，使得volatile表现出了锁的特性

#### 		4.6final中的内存屏障

​		新建对象过程中，构造体中对final域的初始化写入和这个对象赋值给其他引用变量，这两个操作不能重排序

​		初次读包含final域的对象引用和读取这个final域，这两个操作不能重排序（意思就是先赋值引用，再调用final值）

# 计算机网络

#### 		1.TCP协议

​			TCP 是传输层协议，对应 OSI 网络模型的第四层传输层

​			**基于链接**，传输数据的时候需要先建立好链接，然后再进行传输

​			TCP一旦建立，就可以进行**双向通信**	

​			TCP的传输**基于字节流**而不是报文，数据按字节大小进行编号，接收端通过ACK确认收到的数据编号，这样来保证**有序性和完整性**，因此是**可靠性运输**

​			TCP**提供流量控制能力**，通过滑动窗口来控制数据的发送速率

​			TCP还提供阻塞控制，TCP处理阻塞控制主要用到慢启动，拥塞避免，拥塞发生，快速恢复

##### 		**2.TCP三次握手**

​			基于链接，双工传输，**三次握手是为了建立双向的链接**